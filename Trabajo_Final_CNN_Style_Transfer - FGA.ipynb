{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qCY6UbkkI9_N"
   },
   "source": [
    "# Style Transfer\n",
    "\n",
    "<img src=\"https://i0.wp.com/chelseatroy.com/wp-content/uploads/2018/12/neural_style_transfer.png?resize=768%2C311&ssl=1\">\n",
    "\n",
    "La idea de este trabajo final es reproducir el siguiente paper:\n",
    "\n",
    "https://arxiv.org/pdf/1508.06576.pdf\n",
    "\n",
    "El objetivo es transferir el estilo de una imagen dada a otra imagen distinta. \n",
    "\n",
    "Como hemos visto en clase, las primeras capas de una red convolucional se activan ante la presencia de ciertos patrones vinculados a detalles muy pequeños.\n",
    "\n",
    "A medida que avanzamos en las distintas capas de una red neuronal convolucional, los filtros se van activando a medida que detectan patrones de formas cada vez mas complejos.\n",
    "\n",
    "Lo que propone este paper es asignarle a la activación de las primeras capas de una red neuronal convolucional (por ejemplo VGG19) la definición del estilo y a la activación de las últimas capas de la red neuronal convolucional, la definición del contenido.\n",
    "\n",
    "La idea de este paper es, a partir de dos imágenes (una que aporte el estilo y otra que aporte el contenido) analizar cómo es la activación de las primeras capas para la imagen que aporta el estilo y cómo es la activación de las últimas capas de la red convolucional para la imagen que aporta el contenido. A partir de esto se intentará sintetizar una imagen que active los filtros de las primeras capas que se activaron con la imagen que aporta el estilo y los filtros de las últimas capas que se activaron con la imagen que aporta el contenido.\n",
    "\n",
    "A este procedimiento se lo denomina neural style transfer.\n",
    "\n",
    "# En este trabajo se deberá leer el paper mencionado y en base a ello, entender la implementación que se muestra a continuación y contestar preguntas sobre la misma.\n",
    "\n",
    "# Una metodología posible es hacer una lectura rápida del paper (aunque esto signifique no entender algunos detalles del mismo) y luego ir analizando el código y respondiendo las preguntas. A medida que se planteen las preguntas, volviendo a leer secciones específicas del paper terminará de entender los detalles que pudieran haber quedado pendientes.\n",
    "\n",
    "Lo primero que haremos es cargar dos imágenes, una que aporte el estilo y otra que aporte el contenido. A tal fin utilizaremos imágenes disponibles en la web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "colab_type": "code",
    "id": "kyHsa2t0SxZi",
    "outputId": "7c491d8c-ea11-4e66-c51d-42ae47530da7"
   },
   "outputs": [],
   "source": [
    "# Imagen para estilo\n",
    "!wget https://upload.wikimedia.org/wikipedia/commons/5/52/La_noche_estrellada1.jpg\n",
    "\n",
    "# Imagen para contenido\n",
    "!wget https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Neckarfront_T%C3%BCbingen_Mai_2017.jpg/775px-Neckarfront_T%C3%BCbingen_Mai_2017.jpg\n",
    "\n",
    "# Creamos el directorio para los archivos de salida\n",
    "!mkdir /content/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://upload.wikimedia.org/wikipedia/commons/thumb/7/71/2010-kodiak-bear-1.jpg/1280px-2010-kodiak-bear-1.jpg\n",
    "    \n",
    "!wget https://www.zurbaran.com.ar/wp-content/uploads/2014/04/38099quinquela.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NIxH20o2eFoc",
    "outputId": "7dbee2aa-0f67-4bb1-d0b7-0c9d889a7a9a"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "import numpy as np\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "from keras.applications import vgg19\n",
    "from keras import backend as K\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iLkV1bnFl_tK"
   },
   "outputs": [],
   "source": [
    "# Definimos las imagenes que vamos a utilizar, y el directorio de salida\n",
    "\n",
    "#base_image_path = Path(\"/content/775px-Neckarfront_Tübingen_Mai_2017.jpg\")\n",
    "base_image_path = Path(\"/content/1280px-2010-kodiak-bear-1.jpg\")\n",
    "#style_reference_image_path = Path(\"/content/La_noche_estrellada1.jpg\")\n",
    "#style_reference_image_path = Path(\"/content/Ciclista.jpg\")\n",
    "style_reference_image_path = Path(\"/content/38099quinquela.jpg\")\n",
    "result_prefix = Path(\"/content/output\")\n",
    "iterations = 50 #100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gz2PeGfpeYzj"
   },
   "source": [
    "# 1) En base a lo visto en el paper ¿Qué significan los parámetros definidos en la siguiente celda?\n",
    "\n",
    "Respuesta:  \n",
    "\n",
    "Cada uno de ellos es un peso de la loss:\n",
    "\n",
    "**style_weight** = es el peso que tiene el estilo en el calculo de loss. Es el beta en la siguiente formula.\n",
    "\n",
    "**content_weight** = es el peso que tiene el contenido en la loss. Es el alpha en la siguiente fomula.\n",
    "\n",
    "![loss.png](loss.png)\n",
    "\n",
    "**total_variation_weight** = peso de variacion de la imagen consigo misma, el objetivo de esta variable es mantener consistencia entre los pixeles de la imagen resultante.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ABxvBK85CUQR"
   },
   "source": [
    "# Sección nueva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P9Dt3aaEmJWS"
   },
   "outputs": [],
   "source": [
    "total_variation_weight = 0.1   \n",
    "style_weight = 10 \n",
    "content_weight = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CQQJOhCVuse6"
   },
   "outputs": [],
   "source": [
    "# Definimos el tamaño de las imágenes a utilizar\n",
    "width, height = load_img(base_image_path).size     #sube la imagen y calcula el tamaño\n",
    "img_nrows = 400\n",
    "img_ncols = int(width * img_nrows / height)       #calcula la cantidad de columnas a partir ancho por las filas dividido el alto\n",
    "print (img_ncols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gg2ct-8agm1E"
   },
   "source": [
    "# 2) Explicar qué hace la siguiente celda. En especial las últimas dos líneas de la función antes del return. ¿Por qué?\n",
    "\n",
    "Ayuda: https://keras.io/applications/\n",
    "\n",
    "**Respuesta:**\n",
    "Es una funcion donde recibe el path de la imagen, la carga convirtiendola en un array. En la anteultima sentencia,  le agrega una dimension quedando (1,img_nrows, img_ncols,3). \n",
    "Vgg19.preprocess_input(img): preprocesada el array, la cual es convertida de RGB a BGR, centrado en 0 respecto a imageNet, sin escalas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tAkljg4zuzYd"
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(img_nrows, img_ncols))   ## carga la imagen ajustandola al tamaño calculado en la celda anterior\n",
    "    img = img_to_array(img)  #convierte la imagen pil a un numpyp array\n",
    "    img = np.expand_dims(img, axis=0)  #agrega una dimension al array, quedando (1,img_nrows, img_ncols,3)\n",
    "    img = vgg19.preprocess_input(img)  #adecua la imagen al model vgg19\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KTf0YDSagt10"
   },
   "source": [
    "# 3) Habiendo comprendido lo que hace la celda anterior, explique de manera muy concisa qué hace la siguiente celda. ¿Qué relación tiene con la celda anterior?\n",
    "\n",
    "**Respuesta:** \n",
    "En la funcion Deprocess_image se revierten los cambios realizados en la función preprocess_image.\n",
    "\n",
    "Es decir, quita la 4ta dismension agregada en el preprocess, descentra la imagen respecto al cero sumando la media a cada dimension, vuelve a convertirla a RGB y limita los valores entre 0 y 255. En la siguiente convierte a tensor las 3 variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y5LaTrsAu14z"
   },
   "outputs": [],
   "source": [
    "def deprocess_image(x):\n",
    "    x = x.reshape((img_nrows, img_ncols, 3))\n",
    "    # Remove zero-center by mean pixel\n",
    "    x[:, :, 0] += 103.939  #suma 103.939 a la dimension 0  Blue\n",
    "    x[:, :, 1] += 116.779  #suma 116.779 a la dimension 1 Green\n",
    "    x[:, :, 2] += 123.68  #suma 123.68 a la dimension 2  Red\n",
    "    # 'BGR'->'RGB'\n",
    "    x = x[:, :, ::-1]    #invierte el orden de las dimensiones\n",
    "    x = np.clip(x, 0, 255).astype('uint8')     # limita los valores del array entre 0 y 255 enteros\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HYNio09mu4S3"
   },
   "outputs": [],
   "source": [
    "# get tensor representations of our images\n",
    "# K.variable convierte un numpy array en un tensor, para \n",
    "base_image = K.variable(preprocess_image(base_image_path))\n",
    "style_reference_image = K.variable(preprocess_image(style_reference_image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a1Lbw02Uu--o"
   },
   "outputs": [],
   "source": [
    "combination_image = K.placeholder((1, img_nrows, img_ncols, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RJEi0YI3Uzrm"
   },
   "source": [
    "Aclaración:\n",
    "\n",
    "La siguiente celda sirve para procesar las tres imagenes (contenido, estilo y salida) en un solo batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gGO_jGFfvEbF"
   },
   "outputs": [],
   "source": [
    "# combine the 3 images into a single Keras tensor\n",
    "input_tensor = K.concatenate([base_image,\n",
    "                              style_reference_image,\n",
    "                              combination_image], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "tdG59VRavHGB",
    "outputId": "93a0b0ea-2a11-4644-bed6-0165379a6d31"
   },
   "outputs": [],
   "source": [
    "# build the VGG19 network with our 3 images as input\n",
    "# the model will be loaded with pre-trained ImageNet weights\n",
    "model = vgg19.VGG19(input_tensor=input_tensor,\n",
    "                    weights='imagenet', include_top=False)\n",
    "print('Model loaded.')\n",
    "\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "70-vs_jZkKVc"
   },
   "source": [
    "# 4) En la siguientes celdas:\n",
    "\n",
    "- ¿Qué es la matriz de Gram?¿Para qué se usa?\n",
    "\n",
    "Se utiliza para calcular la correlacion entre dos filtros o canales, calculando el producto punto entre los vectores de activacion de los mismos. Es utilizada en la formula de la style_loss. \n",
    "\n",
    "- ¿Por qué se permutan las dimensiones de x?\n",
    "\n",
    "Por defecto los filtros estan en la 3er dimension, los pasa a la 1era dimension a fin de poder hacer el producto interno de estos en la Matriz de Gram y que queden bien ordenados al trasponer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K1FODPATvJ1k"
   },
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
    "    gram = K.dot(features, K.transpose(features))\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vBQkKFY0Rbx-"
   },
   "source": [
    "# 5) Losses:\n",
    "\n",
    "Explicar qué mide cada una de las losses en las siguientes tres celdas.\n",
    "\n",
    "Rta:\n",
    "\n",
    "**Style_loss=**  mide la diferencia del estilo de la imagen de estilo y la generada. Cuanto menor es la loss mas parecido es el estilo entre estas imagenes.\n",
    "\n",
    "**Content_loss=**  mide la diferencia entre el contenido de la imagen base y la imagen generada\n",
    "\n",
    "**total_variation_loss =** es utilizada para calcular la coherencia local en la imagen generada, generando un transicion suave entre los pixeles, penalizando cambios abruptos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1-Gt0ahWvN6q"
   },
   "outputs": [],
   "source": [
    "def style_loss(style, combination):\n",
    "    assert K.ndim(style) == 3\n",
    "    assert K.ndim(combination) == 3\n",
    "    S = gram_matrix(style)\n",
    "    C = gram_matrix(combination)\n",
    "    channels = 3\n",
    "    size = img_nrows * img_ncols\n",
    "    return K.sum(K.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XCqnju5RvQCo"
   },
   "outputs": [],
   "source": [
    "def content_loss(base, combination):\n",
    "    return K.sum(K.square(combination - base))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udEp5h31vRnY"
   },
   "outputs": [],
   "source": [
    "def total_variation_loss(x):\n",
    "    assert K.ndim(x) == 4\n",
    "    a = K.square(\n",
    "        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])\n",
    "    b = K.square(\n",
    "        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n",
    "    return K.sum(K.pow(a + b, 1.25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-65vcinbvTZ0"
   },
   "outputs": [],
   "source": [
    "# Armamos la loss total\n",
    "loss = K.variable(0.0)\n",
    "layer_features = outputs_dict['block5_conv2']\n",
    "base_image_features = layer_features[0, :, :, :]\n",
    "combination_features = layer_features[2, :, :, :]\n",
    "loss = loss + content_weight * content_loss(base_image_features,\n",
    "                                            combination_features)\n",
    "\n",
    "feature_layers = ['block1_conv1', 'block2_conv1',\n",
    "                  'block3_conv1', 'block4_conv1',\n",
    "                  'block5_conv1']\n",
    "for layer_name in feature_layers:\n",
    "    layer_features = outputs_dict[layer_name]\n",
    "    style_reference_features = layer_features[1, :, :, :] \n",
    "    combination_features = layer_features[2, :, :, :]\n",
    "    sl = style_loss(style_reference_features, combination_features)\n",
    "    loss = loss + (style_weight / len(feature_layers)) * sl\n",
    "loss = loss + total_variation_weight * total_variation_loss(combination_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pbz4n1OhvV2K"
   },
   "outputs": [],
   "source": [
    "grads = K.gradients(loss, combination_image)\n",
    "\n",
    "outputs = [loss]\n",
    "if isinstance(grads, (list, tuple)):\n",
    "    outputs += grads\n",
    "else:\n",
    "    outputs.append(grads)\n",
    "\n",
    "f_outputs = K.function([combination_image], outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1JbydbOaVcvU"
   },
   "source": [
    "# 6) Explique el propósito de las siguientes tres celdas. ¿Qué hace la función fmin_l_bfgs_b? ¿En qué se diferencia con la implementación del paper? ¿Se puede utilizar alguna alternativa?\n",
    "\n",
    "Respuesta:\n",
    "Explique el propósito de las siguientes tres celdas. \n",
    "\n",
    "**eval_loss_and_grads:** La primer celda evalua la loss y el gradiente de la imagen ingresada.\n",
    "\n",
    "**class Evaluator:** La segunda celda implementa la clase evaluator donde calcula la loss y el gradiente en forma conjunta.\n",
    "\n",
    "**Generacion de imagenes:**  en la tercer celda se itera la cantidad de iteraciones definido en la variable iterations, tomando la imagen, calcula la minima loss de 20 iteraciones, deprocesa la imagen y la graba como una nueva imagen.\n",
    "\n",
    "\n",
    "¿Qué hace la función fmin_l_bfgs_b? \n",
    "Minimiza la funcion definida en el primer parametro, en este caso la loss.\n",
    "\n",
    "¿En qué se diferencia con la implementación del paper?\n",
    "En esta implementación se utiliza la total_loss que no es nombrada en el paper. En el paper se usa la loss de style y de content.\n",
    "\n",
    "¿Se puede utilizar alguna alternativa?\n",
    "Se podria utilizar Adam o SGD en lugar de fmin_l_bfgs_b. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zVE1_qemvZeN"
   },
   "outputs": [],
   "source": [
    "def eval_loss_and_grads(x):\n",
    "    x = x.reshape((1, img_nrows, img_ncols, 3))\n",
    "    outs = f_outputs([x])\n",
    "    loss_value = outs[0]\n",
    "    if len(outs[1:]) == 1:\n",
    "        grad_values = outs[1].flatten().astype('float64')\n",
    "    else:\n",
    "        grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
    "    return loss_value, grad_values\n",
    "\n",
    "# this Evaluator class makes it possible\n",
    "# to compute loss and gradients in one pass\n",
    "# while retrieving them via two separate functions,\n",
    "# \"loss\" and \"grads\". This is done because scipy.optimize\n",
    "# requires separate functions for loss and gradients,\n",
    "# but computing them separately would be inefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qbl9roIgvdb1"
   },
   "outputs": [],
   "source": [
    "class Evaluator(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grads_values = None\n",
    "\n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "\n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sb0yOEl-WOE6"
   },
   "source": [
    "# 7) Ejecute la siguiente celda y observe las imágenes de salida en cada iteración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "n31YBwCVvhAI",
    "outputId": "7b6791e5-ab64-44c3-d501-45397d53f028"
   },
   "outputs": [],
   "source": [
    "evaluator = Evaluator()\n",
    "\n",
    "# run scipy-based optimization (L-BFGS) over the pixels of the generated image\n",
    "# so as to minimize the neural style loss\n",
    "x = preprocess_image(base_image_path)\n",
    "\n",
    "for i in range(iterations):\n",
    "    print('Start of iteration', i)\n",
    "    start_time = time.time()\n",
    "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n",
    "                                     fprime=evaluator.grads, maxfun=20)\n",
    "    print('Current loss value:', min_val)\n",
    "    # save current generated image\n",
    "    img = deprocess_image(x.copy())\n",
    "    fname = result_prefix / ('output_at_iteration_%d.png' % i)\n",
    "    save_img(fname, img)\n",
    "    end_time = time.time()\n",
    "    print('Image saved as', fname)\n",
    "    print('Iteration %d completed in %ds' % (i, end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SkiJtofbWWy1"
   },
   "source": [
    "# 8) Generar imágenes para distintas combinaciones de pesos de las losses. Explicar las diferencias. (Adjuntar las imágenes generadas como archivos separados.)\n",
    "\n",
    "Respuesta:\n",
    "\n",
    "# 9) Cambiar las imágenes de contenido y estilo por unas elegidas por usted. Adjuntar el resultado.\n",
    "\n",
    "Respuesta:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![oso.png](oso.png width=80px) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imagen original e Imagen de Estilo:**\n",
    "\n",
    "[<img src=\"OSO.png\" width=\"500\"/>](OSO.png)   [<img src=\"quinquela.jpg\" width=\"500\"/>](Quinquela.jpg)\n",
    "\n",
    "**Parametros originales:**   total_variation_weight = 0.1   style_weight = 10  content_weight = 1\n",
    "\n",
    "[<img src=\"\\Quinquela - Oso\\output\\output_at_iteration_49.png\" width=\"600\"/>](output_at_iteration_49.png)\n",
    "\n",
    "**1 - Parametros:**   total_variation_weight = 10   style_weight = 10  content_weight = 100\n",
    "\n",
    "[<img src=\"\\OSO_10_10_100\\output_at_iteration_49.png\" width=\"600\"/>](output_at_iteration_49.png)\n",
    "\n",
    "En esta configuración donde tiene mas peso el contenido que el resto de las variables, se puede apreciar que la imagen resultante esta mejor definida, con trazos mas suaves en las pinceladas, a pesar de que los colores se aproximan a la imagen de estilo.\n",
    "\n",
    "**2 - Parametros:**   total_variation_weight = 10   style_weight = 100  content_weight = 10\n",
    "\n",
    "[<img src=\"\\OSO_10_100_10\\output_at_iteration_49.png\" width=\"600\"/>](output_at_iteration_49.png)\n",
    "\n",
    "En esta imagen el estilo es lo preponderante por lo cual los trazos de la pintura se pueden dislumbrar mas fuertemente, perdiendo en alguna medida la definicion del oso sobre todo en su cabeza.\n",
    "\n",
    "**3 - Parametros:**   total_variation_weight = 100   style_weight = 10  content_weight = 10\n",
    "\n",
    "[<img src=\"\\OSO_100_10_10\\output_at_iteration_49.png\" width=\"600\"/>](output_at_iteration_49.png)\n",
    "\n",
    "Esta imagen resultante, pierde la nitidez, esto se debe a que el mayor peso esta dado en la total_variation_weight. El resultado es una imagen donde no se puede apreciar el estilo de la imagen de estilo ni el contenido de la imagen base. Quedando una imagen casi sin definiciones.\n",
    "\n",
    "En todas las imagenes lo primero que pierde la imagen resultante es la gama de colores de la imagen original, asimilando la paleta de colores a la imagen de estilo.\n",
    "\n",
    "Considero que la configuracion default del tp es la mas adecuada ya que mantiene una buena relacion entre estilo y contenido.\n",
    "\n",
    "Todas las imagenes de las ejecuciones se encuentran en las carpetas adjuntas al trabajo practico, para el mismo se utilizaron 50 iteraciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "OSnKowrnOBXz",
    "outputId": "2515a07b-5dc9-40df-915d-477061939b2e"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Trabajo Final CNN - Style Transfer.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
